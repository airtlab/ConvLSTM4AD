{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ConvLSTM4AD_train&val.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1m2LKTJyfwh9i_fzVpbruUlWUPxL1Bu8x","authorship_tag":"ABX9TyOnO7gCKLebccOVDOy//ieo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"ENHQi_4skexf"},"source":["!git clone https://github.com/airtlab/ConvLSTM4AD\n","\n","#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install simpleitk\n","#!pip show tensorflow\n","#!pip install --upgrade tensorflow\n","\n","import SimpleITK as sitk\n","import os\n","import nibabel as nib\n","import numpy as np\n","import tensorflow as tf\n","\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, models"],"metadata":{"id":"SLbmYqk5rusq"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiExh5uuk7Vb"},"source":["def resample_img(itk_image, out_spacing=[1, 1, 1], is_label=False):\n","    original_spacing = itk_image.GetSpacing()\n","    original_size = itk_image.GetSize()\n","    out_size = [\n","        int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\n","        int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\n","        int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\n","    resample = sitk.ResampleImageFilter()\n","    resample.SetOutputSpacing(out_spacing)\n","    resample.SetSize(out_size)\n","    resample.SetOutputDirection(itk_image.GetDirection())\n","    resample.SetOutputOrigin(itk_image.GetOrigin())\n","    resample.SetTransform(sitk.Transform())\n","    resample.SetDefaultPixelValue(itk_image.GetPixelIDValue())\n","    if is_label:\n","        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n","    else:\n","        resample.SetInterpolator(sitk.sitkBSpline)\n","    return resample.Execute(itk_image)\n","\n","def preprocess(img, out_shape=None):\n","    if out_shape is not None:\n","        img = resize(img, out_shape, mode='constant')\n","    \n","    mean = img.mean() \n","    std = img.std() \n","    return (img - mean) / std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BlCay8WlEmF"},"source":["img_path = \"/content/ConvLSTM4AD/Merged_dataset/Dataset\"\n","img_height, img_width = 256, 256 \n","seq_len = 5\n","\n","X = [] # an empty list ‘X’ is generated\n","Y = [] # an empty list ‘Y’ is generated\n","\n","dir = img_path # the content of the string ‘img_path’ is stored in a new string ‘dir’ to simplify its subsequent usage\n","classes = [\"AD\",\"CN\"] \n","classes_list = os.listdir(dir) # a list containing the names of the elements inside ‘dir’ is generated\n","classes_list.sort() # the list is sorted to have AD as first element and CN as second one\n","\n","full_path_AD = os.path.join(dir, classes_list[0]) # the path of the AD directory is obtained joining ‘dir’ with the first element of ‘classes_list’\n","samples_AD = os.listdir(full_path_AD) # a list containing the names of the elements inside the AD directory is generated \n","samples_AD.sort() # the sample names are sorted alphabetically \n","for a in samples_AD: \n","  b = os.path.join(full_path_AD, a) # the file path is stored joining ‘full_path_AD’ with the current sample name ‘a’ \n","  my_img = nib.load(b) \n","  nii_data = my_img.get_fdata() \n","  my_img.uncache()\n","  del my_img\n","  temp = [] # a new empty list ‘temp’ is generated\n","  for i in range(0,5): \n","    temp.append(preprocess(nii_data[:,:,i]))\n","  X.append(temp) # once all slices have been appended, ‘temp’ is appended to the ‘X’ list\n","  y = [0]*len(classes_list) # a 1x2 array ‘y’ filled with zeros is generated\n","  y[1] = 1 # 1 is assigned to the second column of the array ([0,1] is the AD label)\n","  Y.append(y) # the ‘y’ array is appended to the ‘Y’ list\n","\n","full_path_CN = os.path.join(dir, classes_list[1]) # the path of the CN directory is obtained joining ‘dir’ with the second element of ‘classes_list’\n","samples_CN = os.listdir(full_path_CN) \n","samples_CN.sort()\n","for a in samples_CN: \n","  b = os.path.join(full_path_CN, a)\n","  my_img = nib.load(b) \n","  nii_data = my_img.get_fdata() \n","  my_img.uncache()\n","  del my_img\n","  temp = []\n","  for i in range(0,5): \n","    temp.append(preprocess(nii_data[:,:,i]))\n","  X.append(temp)\n","  y = [0]*len(classes_list)\n","  y[0] = 1 # 1 is assigned to the first column of the array ([1,0] is the CN label)\n","  Y.append(y)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DY7oHqu4lFae"},"source":["X = np.asarray(X) # ‘X’ is turned into a numpy array\n","X = X[...,np.newaxis] # a new axis is added to ‘X’ to match the shape requested by the training function\n","\n","Y = np.asarray(Y) # the same for ‘Y’\n","\n","#print(X.shape)\n","#print(Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoZxHG5Zm01Q"},"source":["seed = 0 \n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, \n","                                                    shuffle=True, random_state=seed) # split in train (train+val) and test: 80% of the total dataset for train+val and 20% for test \n","                                                                                     # ‘shuffle’ shuffles all data before splitting\n","                                                                                     # ‘random_state’ controls the shuffling: each integer is related to a specific shuffle\n","\n","del X\n","del Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdhWoYKXnScG"},"source":["model = models.Sequential()\n","model.add(layers.ConvLSTM2D(filters=32, \n","                            kernel_size=(3,3), \n","                            return_sequences=False, \n","                            data_format=\"channels_last\", \n","                            input_shape=(seq_len,img_height,img_width,1)))\n","model.add(layers.Dropout(0.5)) \n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation=\"relu\"))\n","model.add(layers.Dropout(0.5)) \n","model.add(layers.Dense(2, activation=\"softmax\"))\n","\n","#model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qj4k6SisnWFr"},"source":["opt = tf.keras.optimizers.SGD(learning_rate=0.001) \n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n","\n","earlystop = tf.keras.callbacks.EarlyStopping(patience=7)\n","callbacks = [earlystop]\n","history = model.fit(x=X_train, y=Y_train, epochs=40, batch_size=4, shuffle=True, validation_split=0.2, callbacks=callbacks)"],"execution_count":null,"outputs":[]}]}