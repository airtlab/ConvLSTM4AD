{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OASIS3+ADNI1S_CNvsAD_bestmodel.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOWfcc2PZn+FGUyganCM63l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"ENHQi_4skexf"},"source":["!git clone https://github.com/airtlab/ConvLSTM4AD\r\n","\r\n","!gdown --id 1FIc_Q47m6F0HjOuURbgjrRihbc9_uced -O ConvLSTM4AD/bestmodel.h5\r\n","\r\n","#from google.colab import drive\r\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"csyKjNJ-k6pI"},"source":["#!pip show tensorflow\r\n","#!pip install --upgrade tensorflow\r\n","import tensorflow as tf\r\n","from tensorflow.keras import datasets, layers, models\r\n","from sklearn import model_selection\r\n","from sklearn.metrics import classification_report\r\n","import os\r\n","import nibabel as nib\r\n","import cv2\r\n","import numpy as np\r\n","!pip install simpleitk\r\n","import SimpleITK as sitk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiExh5uuk7Vb"},"source":["img_path = \"/content/ConvLSTM4AD/Merged_dataset/Dataset\"\r\n","img_height, img_width = 256, 256 \r\n","seq_len = 5\r\n","\r\n","\r\n","# Read \r\n","def read_img(img_path):\r\n","    return sitk.GetArrayFromImage(sitk.ReadImage(img_path)) \r\n","\r\n","# Resample to 1 mm\r\n","def resample_img(itk_image, out_spacing=[1, 1, 1], is_label=False):\r\n","    original_spacing = itk_image.GetSpacing()\r\n","    original_size = itk_image.GetSize()\r\n","    out_size = [\r\n","        int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\r\n","        int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\r\n","        int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\r\n","    resample = sitk.ResampleImageFilter()\r\n","    resample.SetOutputSpacing(out_spacing)\r\n","    resample.SetSize(out_size)\r\n","    resample.SetOutputDirection(itk_image.GetDirection())\r\n","    resample.SetOutputOrigin(itk_image.GetOrigin())\r\n","    resample.SetTransform(sitk.Transform())\r\n","    resample.SetDefaultPixelValue(itk_image.GetPixelIDValue())\r\n","    if is_label:\r\n","        resample.SetInterpolator(sitk.sitkNearestNeighbor)\r\n","    else:\r\n","        resample.SetInterpolator(sitk.sitkBSpline)\r\n","    return resample.Execute(itk_image)\r\n","\r\n","def preprocess(img, out_shape=None):\r\n","    if out_shape is not None:\r\n","        img = resize(img, out_shape, mode='constant')\r\n","    \r\n","    # Input normalization\r\n","    mean = img.mean() \r\n","    std = img.std() \r\n","    return (img - mean) / std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BlCay8WlEmF"},"source":["X = []\r\n","Y = []\r\n","\r\n","d = img_path\r\n","classes = [\"AD\",\"CN\"]\r\n","classes_list = os.listdir(d) \r\n","sorted(classes_list)\r\n","print(classes_list[0]) \r\n","print(classes_list[1]) \r\n","\r\n","full_path = os.path.join(d,classes_list[0]) # AD\r\n","for p2 in os.listdir(full_path): \r\n","  p3 = os.path.join(full_path,p2) \r\n","  my_img = nib.load(p3) \r\n","  nii_data = my_img.get_fdata() \r\n","  my_img.uncache()\r\n","  del my_img\r\n","  temp = []\r\n","  for i in range(0,5): \r\n","    temp.append(cv2.resize(nii_data[:,:,i],(256,256)))\r\n","  X.append(temp)\r\n","  y = [0]*len(classes_list)\r\n","  y[1] = 1\r\n","  Y.append(y) # label [0,1]\r\n","\r\n","full_path1 = os.path.join(d,classes_list[1]) # CN\r\n","for p2 in os.listdir(full_path1): \r\n","  p3 = os.path.join(full_path1,p2) \r\n","  my_img = nib.load(p3) \r\n","  nii_data = my_img.get_fdata() \r\n","  my_img.uncache()\r\n","  del my_img\r\n","  temp = []\r\n","  for i in range(0,5): \r\n","    temp.append(cv2.resize(nii_data[:,:,i],(256,256)))\r\n","  X.append(temp)\r\n","  y = [0]*len(classes_list)\r\n","  y[0] = 1\r\n","  Y.append(y) # label [1,0] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DY7oHqu4lFae","executionInfo":{"status":"ok","timestamp":1607871262656,"user_tz":-60,"elapsed":2489,"user":{"displayName":"AIRTLab DII","photoUrl":"","userId":"06782619084140121985"}},"outputId":"e3e5f7ff-555e-40d7-f021-4c4bcca9e920"},"source":["X = np.asarray(X)\r\n","Y = np.asarray(Y)\r\n","\r\n","X = X[...,np.newaxis]\r\n","print(X.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(427, 5, 256, 256, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UoZxHG5Zm01Q"},"source":["X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X, Y, test_size = 0.20, shuffle = True, random_state = 0)\r\n","\r\n","print(\"Number of training samples: \" + str(len(X_train)))\r\n","print(\"Number of test samples: \" + str(len(X_test)))\r\n","\r\n","del X\r\n","del Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdhWoYKXnScG","executionInfo":{"status":"ok","timestamp":1607874176756,"user_tz":-60,"elapsed":1090,"user":{"displayName":"AIRTLab DII","photoUrl":"","userId":"06782619084140121985"}},"outputId":"432f0473-e1d1-4c61-bde8-003afde469f2"},"source":["model = models.Sequential()\r\n","\r\n","model.add(layers.ConvLSTM2D(filters=32, \r\n","                            kernel_size=(3,3), \r\n","                            return_sequences=False, \r\n","                            data_format=\"channels_last\", \r\n","                            input_shape=(seq_len,img_height,img_width, 1)))\r\n","model.add(layers.Dropout(0.5)) \r\n","model.add(layers.Flatten())\r\n","model.add(layers.Dense(256, activation=\"relu\"))\r\n","model.add(layers.Dropout(0.5)) \r\n","model.add(layers.Dense(2, activation=\"softmax\"))\r\n","\r\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv_lst_m2d_1 (ConvLSTM2D)  (None, 254, 254, 32)      38144     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 254, 254, 32)      0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2064512)           0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               528515328 \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 514       \n","=================================================================\n","Total params: 528,553,986\n","Trainable params: 528,553,986\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qj4k6SisnWFr","executionInfo":{"status":"ok","timestamp":1607875896017,"user_tz":-60,"elapsed":1716448,"user":{"displayName":"AIRTLab DII","photoUrl":"","userId":"06782619084140121985"}},"outputId":"10f04368-9791-490d-b4bf-7c33a7337db6"},"source":["opt = tf.keras.optimizers.SGD(learning_rate=0.001) \r\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\r\n","\r\n","earlystop = tf.keras.callbacks.EarlyStopping(patience=7)\r\n","callbacks = [earlystop]\r\n","\r\n","history = model.fit(x=X_train, y=Y_train, epochs=40, batch_size=4, shuffle=True, validation_split=0.2, callbacks=callbacks) # training"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","68/68 [==============================] - 112s 2s/step - loss: 2.3457 - accuracy: 0.6765 - val_loss: 0.4443 - val_accuracy: 0.8116\n","Epoch 2/40\n","68/68 [==============================] - 112s 2s/step - loss: 0.4211 - accuracy: 0.7721 - val_loss: 0.4141 - val_accuracy: 0.8406\n","Epoch 3/40\n","68/68 [==============================] - 112s 2s/step - loss: 0.3464 - accuracy: 0.8493 - val_loss: 0.4261 - val_accuracy: 0.7971\n","Epoch 4/40\n","68/68 [==============================] - 112s 2s/step - loss: 0.3086 - accuracy: 0.8640 - val_loss: 0.6287 - val_accuracy: 0.7681\n","Epoch 5/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.2883 - accuracy: 0.8713 - val_loss: 0.3970 - val_accuracy: 0.7826\n","Epoch 6/40\n","68/68 [==============================] - 112s 2s/step - loss: 0.2519 - accuracy: 0.8713 - val_loss: 0.4152 - val_accuracy: 0.7391\n","Epoch 7/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.2524 - accuracy: 0.8713 - val_loss: 0.4168 - val_accuracy: 0.7681\n","Epoch 8/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.2118 - accuracy: 0.8897 - val_loss: 0.3738 - val_accuracy: 0.8406\n","Epoch 9/40\n","68/68 [==============================] - 112s 2s/step - loss: 0.2449 - accuracy: 0.8787 - val_loss: 0.4041 - val_accuracy: 0.7826\n","Epoch 10/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.1941 - accuracy: 0.9228 - val_loss: 0.4732 - val_accuracy: 0.7246\n","Epoch 11/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.1982 - accuracy: 0.8971 - val_loss: 0.3966 - val_accuracy: 0.8261\n","Epoch 12/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.2012 - accuracy: 0.9118 - val_loss: 0.4243 - val_accuracy: 0.7391\n","Epoch 13/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.1586 - accuracy: 0.9265 - val_loss: 0.4314 - val_accuracy: 0.7681\n","Epoch 14/40\n","68/68 [==============================] - 113s 2s/step - loss: 0.1521 - accuracy: 0.9485 - val_loss: 0.5088 - val_accuracy: 0.7681\n","Epoch 15/40\n","68/68 [==============================] - 112s 2s/step - loss: 0.1436 - accuracy: 0.9412 - val_loss: 0.4923 - val_accuracy: 0.7536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XU-TKoVynZUI"},"source":["model.save('drive/MyDrive/Progetto_IA_L_Gianvittorio/Selene/4paper/Best_model/OASIS3+ADNI1S_CNvsAD_bestmodel.h5')"],"execution_count":null,"outputs":[]}]}